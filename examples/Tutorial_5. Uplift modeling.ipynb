{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install LightAutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if doesn't clone repository by git. (ex.: colab, kaggle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.utils.profiler import Profiler\n",
    "\n",
    "from lightautoml.addons.uplift.base import AutoML, AutoUplift, AutoUpliftTX, BaseLearnerWrapper, MetaLearnerWrapper, Wrapper\n",
    "from lightautoml.addons.uplift import meta_learners\n",
    "from lightautoml.addons.uplift.metrics import (_available_uplift_modes,\n",
    "                                               TUpliftMetric,\n",
    "                                               calculate_graphic_uplift_curve,\n",
    "                                               calculate_min_max_uplift_auc,\n",
    "                                               calculate_uplift_at_top,\n",
    "                                               calculate_uplift_auc,\n",
    "                                               perfect_uplift_curve)\n",
    "from lightautoml.addons.uplift.utils import create_linear_automl\n",
    "from lightautoml.report.report_deco import ReportDecoUplift\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name\n",
    "TREATMENT_NAME = 'CODE_GENDER'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix torch number of threads and numpy seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset from the repository if doesn't clone repository by git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './example_data/test_data_files'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/sberbank-ai-lab/LightAutoML/master/example_data/test_data_files/sampled_app_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(DATASET_FULLNAME):\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = requests.get(DATASET_URL).text\n",
    "    with open(DATASET_FULLNAME, 'w') as output:\n",
    "        output.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = pd.read_csv('./example_data/test_data_files/sampled_app_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Some user feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "data['CODE_GENDER'] = (data['CODE_GENDER'] == 'M').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting for train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "stratify_value = data[TARGET_NAME] + 10 * data[TREATMENT_NAME]\n",
    "\n",
    "train, test = train_test_split(data, test_size=3000, stratify=stratify_value, random_state=42)\n",
    "\n",
    "test_target, test_treatment = test[TARGET_NAME].values.ravel(), test[TREATMENT_NAME].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup columns roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'treatment': TREATMENT_NAME,\n",
    "    DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoUplift (use predefined uplift methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "autouplift = AutoUplift(task,\n",
    "                        add_dd_candidates=True,\n",
    "                        metric='adj_qini', \n",
    "                        normed_metric=True, \n",
    "                        test_size=0.2, \n",
    "                        threshold_imbalance_treatment=0.0,\n",
    "                        timeout=100)\n",
    "\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_ranting()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get best metalearner with report functionaly (should refit on train data for generating report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "best_metalearner_repo = autouplift.create_best_metalearner(need_report=True, update_metalearner_params={'timeout': 100})\n",
    "best_metalearner_repo.fit(train, roles)\n",
    "best_metalearner_repo.predict(test)\n",
    "\n",
    "# Path to report: PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = autouplift.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoUplift (custom uplift methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set uplift candidate for choosing best of them\n",
    "# !!!ATTENTION!!!\n",
    "#    This is a demonstration of the possibilities, \n",
    "#    You may use default set of candidates \n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "uplift_candidates = [\n",
    "    MetaLearnerWrapper(\n",
    "        name='TLearner__Default', \n",
    "        klass=meta_learners.TLearner, \n",
    "        params={'base_task': task}\n",
    "    ),  \n",
    "    MetaLearnerWrapper(\n",
    "        name='TLearner__Custom', \n",
    "        klass=meta_learners.TLearner, \n",
    "        params={\n",
    "            'treatment_learner': BaseLearnerWrapper(\n",
    "                name='__TabularAutoML__',\n",
    "                klass=TabularAutoML, \n",
    "                params={'task': task, 'timeout': 10}),\n",
    "            'control_learner': BaseLearnerWrapper(\n",
    "                name='__Linear__',\n",
    "                klass=create_linear_automl,\n",
    "                params={'task': Task('binary')})\n",
    "        }\n",
    "    ),\n",
    "    MetaLearnerWrapper(\n",
    "        name='XLearner__Custom',\n",
    "        klass=meta_learners.XLearner,\n",
    "        params={\n",
    "            'outcome_learners': [\n",
    "                TabularAutoML(task=task, timeout=10), # [sec] , Only speed up example, don't change it!\n",
    "                create_linear_automl(task=Task('binary'))\n",
    "            ],\n",
    "            'effect_learners': [BaseLearnerWrapper(\n",
    "                name='__TabularAutoML__',\n",
    "                klass=TabularAutoML, \n",
    "                params={'task': Task('reg'), 'timeout': 5})],\n",
    "            'propensity_learner': create_linear_automl(task=Task('binary')),\n",
    "        }    \n",
    "    )\n",
    "]\n",
    "\n",
    "autouplift = AutoUplift(task,\n",
    "                        uplift_candidates=uplift_candidates, \n",
    "                        add_dd_candidates=True,\n",
    "                        metric='adj_qini', \n",
    "                        normed_metric=True, \n",
    "                        test_size=0.2, \n",
    "                        threshold_imbalance_treatment=0.0,    # Doesn't affect, see warnings\n",
    "                        timeout=600)                          # Doesn't affect, see warnings\n",
    "\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_ranting()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = autouplift.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get best metalearner with report functionaly (should refit on train data for generating report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "best_metalearner_repo = autouplift.create_best_metalearner(need_report=False, update_metalearner_params={'timeout': 60})\n",
    "best_metalearner_repo.fit(train, roles)\n",
    "best_metalearner_repo.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoUplift with custom metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Using a custom metric\n",
    "# How to determine custom metric, see below\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "\n",
    "class CustomUpliftMetric(TUpliftMetric):\n",
    "    def __call__(self, target: np.ndarray, uplift_pred: np.ndarray, treatment: np.ndarray) -> float:\n",
    "        up_10 = calculate_uplift_at_top(target, uplift_pred, treatment, 10)\n",
    "        up_20 = calculate_uplift_at_top(target, uplift_pred, treatment, 20)\n",
    "    \n",
    "        return 0.5 * (up_10 + up_20)\n",
    "\n",
    "autouplift = AutoUplift(task,\n",
    "                        add_dd_candidates=True,\n",
    "                        metric=CustomUpliftMetric(), \n",
    "                        normed_metric=True, \n",
    "                        test_size=0.2, \n",
    "                        threshold_imbalance_treatment=0.0,\n",
    "                        cpu_limit=10,\n",
    "                        timeout=100)\n",
    "\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_ranting()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get best metalearner with report functionaly (should refit on train data for generating report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Warning: can't create best metalearner with report functionaly when custom metric is defined.\n",
    "# Return just best metalearner\n",
    "\n",
    "best_metalearner_repo = autouplift.create_best_metalearner(need_report=True, update_metalearner_params={'timeout': 60})\n",
    "best_metalearner_repo.fit(train, roles)\n",
    "best_metalearner_repo.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoUpliftTX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "autouplift = AutoUpliftTX(Task('binary'), timeout=180)\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_ranting()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = autouplift.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get best metalearner with report functionaly (should refit on train data for generating report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "best_metalearner_repo = autouplift.create_best_metalearner(need_report=True, update_metalearner_params={'timeout': 100})\n",
    "best_metalearner_repo.fit(train, roles)\n",
    "best_metalearner_repo.predict(test)\n",
    "\n",
    "# Path to report: PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The list of baselearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The list of baselearners will be used for each stage.\n",
    "# Names of baselearnerwrapper should be unique, but if not is will be renamed.\n",
    "\n",
    "autouplift = AutoUpliftTX(\n",
    "    Task('binary'),\n",
    "    baselearners = [\n",
    "        BaseLearnerWrapper(\n",
    "            name='__Linear__',\n",
    "            klass=create_linear_automl,\n",
    "            params={}\n",
    "        )\n",
    "    ],\n",
    "    metalearners=['XLearner'],\n",
    "    timeout=120,\n",
    "    timeout_single_learner=15\n",
    ")\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Several stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Specified stage with baselearners\n",
    "# For remain stages will be used default baselearners\n",
    "\n",
    "blw_lin = BaseLearnerWrapper(\n",
    "    name='__Linear__',\n",
    "    klass=create_linear_automl,\n",
    "    params={'task': Task('binary')}\n",
    ")\n",
    "\n",
    "blw_tab = BaseLearnerWrapper(\n",
    "    name='__TabularAutoML__',\n",
    "    klass=TabularAutoML,\n",
    "    params={'task': Task('binary'), 'timeout': 60}\n",
    ")\n",
    "\n",
    "autouplift = AutoUpliftTX(\n",
    "    Task('binary'),\n",
    "    baselearners = {\n",
    "        ('propensity',): [deepcopy(blw_lin)],\n",
    "        ('outcome_control',): [deepcopy(blw_lin)],\n",
    "        ('outcome_treatment',): [deepcopy(blw_tab)],\n",
    "    },\n",
    "    timeout=None,\n",
    "    timeout_single_learner=30\n",
    ")\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Default setting\n",
    "tlearner = meta_learners.TLearner(base_task=Task('binary'), cpu_limit=5)\n",
    "tlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = tlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Custom base algorithm\n",
    "xlearner = meta_learners.XLearner(\n",
    "    propensity_learner=TabularAutoML(task=Task('binary'), timeout=10),\n",
    "    outcome_learners=[\n",
    "        TabularAutoML(task=Task('binary'), timeout=10),\n",
    "        TabularAutoML(task=Task('binary'), timeout=10)\n",
    "    ],\n",
    "    effect_learners=[\n",
    "        TabularAutoML(task=Task('reg'), timeout=10),\n",
    "        TabularAutoML(task=Task('reg'), timeout=10)\n",
    "    ]\n",
    ")\n",
    "xlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = xlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift metrics and graphics (using xlearner predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "UPLIFT_METRIC = 'adj_qini'\n",
    "\n",
    "logging.info(\"All available uplift metrics: %s\", _available_uplift_modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm uplift curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Algorithm curve\n",
    "xs_xlearner, ys_xlearner = calculate_graphic_uplift_curve(\n",
    "    test_target, uplift_pred, test_treatment, mode=UPLIFT_METRIC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, perfect curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline curve\n",
    "xs_base, ys_base = [0, 1], [0, ys_xlearner[-1]]\n",
    "\n",
    "# Perfect curver\n",
    "perfect_uplift = perfect_uplift_curve(test_target, test_treatment)\n",
    "xs_perfect, ys_perfect = calculate_graphic_uplift_curve(\n",
    "    test_target, perfect_uplift, test_treatment, mode=UPLIFT_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(xs_base, ys_base, 'black')\n",
    "plt.plot(xs_xlearner, ys_xlearner, 'red')\n",
    "plt.plot(xs_perfect, ys_perfect, 'green')\n",
    "\n",
    "plt.fill_between(xs_xlearner, ys_xlearner, alpha=0.5, color='orange')\n",
    "\n",
    "plt.xlabel('Cumulative percentage of people in T/C groups')\n",
    "plt.ylabel('Uplift metric (%s)'.format(UPLIFT_METRIC))\n",
    "plt.grid()\n",
    "plt.legend(['Baseline', 'XLearner', 'Perfect']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uplift TOP-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = np.arange(5, 101, 5)\n",
    "\n",
    "uplift_at_tops = []\n",
    "for top in tops:\n",
    "    uat = calculate_uplift_at_top(test_target, uplift_pred, test_treatment, top=top)\n",
    "    uplift_at_tops.append(uat)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(tops, uplift_at_tops, marker='.')\n",
    "\n",
    "plt.legend(['Uplift_At_K'])\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric can be used in AutoUplift(AutoUpliftTX).\n",
    "# There msut be a function's signature:\n",
    "# def custom_metric(target, uplift_pred, treatment) -> float:\n",
    "\n",
    "\n",
    "class CustomUpliftMetric(TUpliftMetric):\n",
    "    def __call__(self, target: np.ndarray, uplift_pred: np.ndarray, treatment: np.ndarray) -> float:\n",
    "        up_10 = calculate_uplift_at_top(target, uplift_pred, treatment, 10)\n",
    "        up_20 = calculate_uplift_at_top(target, uplift_pred, treatment, 20)\n",
    "    \n",
    "        return 0.5 * (up_10 + up_20)\n",
    "\n",
    "\n",
    "metric = CustomUpliftMetric()\n",
    "metric_value = metric(test_target, uplift_pred, test_treatment)\n",
    "\n",
    "print(\"Metric = {}\".format(metric_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RDU = ReportDecoUplift()\n",
    "tlearner_deco = RDU(meta_learners.TLearner(base_task=Task('binary')))\n",
    "tlearner_deco.fit(train, roles)\n",
    "tlearner_deco.predict(test);\n",
    "\n",
    "# Path to report: PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
