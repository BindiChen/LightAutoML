{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1. Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "from lightautoml.ml_algo.boost_lgbm import BoostLGBM\n",
    "from lightautoml.ml_algo.tuning.optuna import OptunaTuner\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBSeqSimpleFeatures, LGBMultiSeqSimpleFeatures\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ImportanceCutoffSelector, ModelBasedImportanceEstimator\n",
    "from lightautoml.reader.base import PandasToPandasReader, DictToNumpySeqReader\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.automl.blend import WeightedBlender\n",
    "from lightautoml.dataset.seq_np_pd_dataset import SeqNumpyPandasDataset\n",
    "from lightautoml.dataset.roles import NumericRole, CategoryRole, DatetimeRole\n",
    "from lightautoml.dataset.np_pd_dataset import NumpyDataset, PandasDataset\n",
    "from lightautoml.ml_algo.random_forest import RandomForestSklearn\n",
    "from lightautoml.validation.np_iterators import TimeSeriesIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/home/simakovde/hdd/kaggle/idao21_final/idao_2021_train'\n",
    "train = pd.read_csv(f'{DATA_FOLDER}/funnel.csv' )\n",
    "\n",
    "clients = pd.read_csv(f'{DATA_FOLDER}/client.csv')\n",
    "deals = pd.read_csv(f'{DATA_FOLDER}/deals.csv')\n",
    "aum = pd.read_csv(f'{DATA_FOLDER}/aum.csv')\n",
    "trxn = pd.read_csv(f'{DATA_FOLDER}/trxn.csv')\n",
    "com = pd.read_csv(f'{DATA_FOLDER}/com.csv')\n",
    "appl = pd.read_csv(f'{DATA_FOLDER}/appl.csv')\n",
    "payments = pd.read_csv(f'{DATA_FOLDER}/payments.csv')\n",
    "balance = pd.read_csv(f'{DATA_FOLDER}/balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, clients.shape, deals.shape, aum.shape, trxn.shape, com.shape, appl.shape, payments.shape, balance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в доп таблицах только данные текущих актуальных клиентов <- реализован\n",
    "# в доп таблицах данные для всех клиентов\n",
    "# в доп таблицах данные только для новых клиентов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_params = {'clients': {'case': 'ids',\n",
    "                          'params': {},\n",
    "                          'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                         }\n",
    "             }\n",
    "\n",
    "X_train = {'plain':train , 'seq': None}\n",
    "task = Task('binary', metric='logloss')\n",
    "\n",
    "roles={'target': 'sale_flg', 'drop': ['sale_amount', 'contacts']}\n",
    "\n",
    "reader = DictToNumpySeqReader(task=task, cv=3, seq_params=seq_params)\n",
    "\n",
    "feats = LGBMultiSeqSimpleFeatures()\n",
    "model = BoostLGBM()\n",
    "pipeline_lvl1 = MLPipeline([model], pre_selection=None, features_pipeline=feats, post_selection=None)\n",
    "\n",
    "automl = AutoML(reader, [\n",
    "    [pipeline_lvl1],\n",
    "], skip_conn=False)\n",
    "\n",
    "oof_pred = automl.fit_predict(X_train, roles=roles, verbose=4)\n",
    "\n",
    "metric_l = log_loss(train[roles['target']], oof_pred.data[:, 0])\n",
    "metric_a = roc_auc_score(train[roles['target']], oof_pred.data[:, 0])\n",
    "\n",
    "print('=============')\n",
    "print(f'log-loss: {metric_l}, roc_auc: {metric_a}')\n",
    "\n",
    "_pred = automl.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seq_params = {'trxn': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       }\n",
    "             }\n",
    "\n",
    "X_train = {'plain':train , 'seq': {'trxn': trxn}}\n",
    "\n",
    "task = Task('binary', metric='logloss')\n",
    "\n",
    "roles={'target': 'sale_flg', 'drop': ['sale_amount', 'contacts']}\n",
    "\n",
    "reader = DictToNumpySeqReader(task=task, cv=3, seq_params=seq_params)\n",
    "\n",
    "feats = LGBMultiSeqSimpleFeatures()\n",
    "model = BoostLGBM()\n",
    "pipeline_lvl1 = MLPipeline([model], pre_selection=None, features_pipeline=feats, post_selection=None)\n",
    "\n",
    "automl = AutoML(reader, [\n",
    "    [pipeline_lvl1],\n",
    "], skip_conn=False)\n",
    "\n",
    "oof_pred = automl.fit_predict(X_train, roles=roles, verbose=3)\n",
    "\n",
    "metric_l = log_loss(train[roles['target']], oof_pred.data[:, 0])\n",
    "metric_a = roc_auc_score(train[roles['target']], oof_pred.data[:, 0])\n",
    "\n",
    "print('=============')\n",
    "print(f'log-loss: {metric_l}, roc_auc: {metric_a}')\n",
    "\n",
    "_pred = automl.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seq_params = {'clients': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id', 'type': 'lookup'}\n",
    "                         }\n",
    "             }\n",
    "\n",
    "X_train = {'plain':train , 'seq': {'clients': clients}}\n",
    "task = Task('binary', metric='logloss')\n",
    "\n",
    "roles={'target': 'sale_flg', 'drop': ['sale_amount', 'contacts']}\n",
    "\n",
    "reader = DictToNumpySeqReader(task=task, cv=3, seq_params=seq_params)\n",
    "\n",
    "feats = LGBMultiSeqSimpleFeatures()\n",
    "model = BoostLGBM()\n",
    "pipeline_lvl1 = MLPipeline([model], pre_selection=None, features_pipeline=feats, post_selection=None)\n",
    "\n",
    "automl = AutoML(reader, [\n",
    "    [pipeline_lvl1],\n",
    "], skip_conn=False)\n",
    "\n",
    "oof_pred = automl.fit_predict(X_train, roles=roles, verbose=3)\n",
    "\n",
    "metric_l = log_loss(train[roles['target']], oof_pred.data[:, 0])\n",
    "metric_a = roc_auc_score(train[roles['target']], oof_pred.data[:, 0])\n",
    "\n",
    "print('=============')\n",
    "print(f'log-loss: {metric_l}, roc_auc: {metric_a}')\n",
    "\n",
    "_pred = automl.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seq_params = {'balance': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       }, \n",
    "              'payments': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       }, \n",
    "              'appl': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       },\n",
    "              'com': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       },\n",
    "              'trxn': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       },\n",
    "              'aum': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       },\n",
    "              'deals': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id'}\n",
    "                       },\n",
    "              'clients': {'case': 'ids',\n",
    "                       'params': {},\n",
    "                       'scheme': {'to': 'plain', 'from_id': 'client_id', 'to_id': 'client_id', 'type': 'lookup'}\n",
    "                       }\n",
    "             }\n",
    "X_train = {'plain':train ,\n",
    "           'seq': {'balance': balance,\n",
    "                   'payments': payments,\n",
    "                   'appl': appl,\n",
    "                   'com': com,\n",
    "                   'trxn': trxn,\n",
    "                   'aum': aum,\n",
    "                   'deals': deals,\n",
    "                   'clients': clients}}\n",
    "\n",
    "task = Task('binary', metric='logloss')\n",
    "\n",
    "roles={'target': 'sale_flg', 'drop': ['sale_amount', 'contacts']}\n",
    "\n",
    "reader = DictToNumpySeqReader(task=task, cv=3, seq_params=seq_params)\n",
    "\n",
    "feats = LGBMultiSeqSimpleFeatures()\n",
    "model = BoostLGBM()\n",
    "pipeline_lvl1 = MLPipeline([model], pre_selection=None, features_pipeline=feats, post_selection=None)\n",
    "\n",
    "automl = AutoML(reader, [\n",
    "    [pipeline_lvl1],\n",
    "], skip_conn=False)\n",
    "\n",
    "oof_pred = automl.fit_predict(X_train, roles=roles, verbose=3)\n",
    "\n",
    "metric_l = log_loss(train[roles['target']], oof_pred.data[:, 0])\n",
    "metric_a = roc_auc_score(train[roles['target']], oof_pred.data[:, 0])\n",
    "\n",
    "print('=============')\n",
    "print(f'log-loss: {metric_l}, roc_auc: {metric_a}')\n",
    "\n",
    "_pred = automl.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
